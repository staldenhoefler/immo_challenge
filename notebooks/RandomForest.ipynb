{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import src.dataPipeline as dataPipeline\n",
    "import importlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "# Evaluating the model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error,r2_score ,make_scorer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "importlib.reload(dataPipeline)\n"
   ],
   "id": "e6963b45d00cd25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_metrics(X_train, y_test, y_pred):\n",
    "    n = len(y_test)  # Number of observations\n",
    "    k = X_train.shape[1]  # Number of predictors\n",
    "    r2 = round(r2_score(y_test, y_pred), 4)\n",
    "    R2_adjusted = round(1 - (1 - r2) * (n - 1) / (n - k - 1), 4)\n",
    "    mape = round(mean_absolute_percentage_error(y_test, y_pred) * 100, 4)\n",
    "    return r2, R2_adjusted, mape"
   ],
   "id": "2ff8ea065ec68e96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def manual_cv_score(X, y, cv, model):\n",
    "    fold_train_mapes = []\n",
    "    fold_test_mapes = []\n",
    "\n",
    "    # Manual CV loop\n",
    "    for train_idx, test_idx in cv.split(X):\n",
    "        # Split the data for this fold\n",
    "        X_tr, X_te = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_tr, y_te = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # Fit the model\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        # Predict on training fold\n",
    "        y_tr_pred = model.predict(X_tr)\n",
    "        fold_train_mapes.append(mean_absolute_percentage_error(y_tr, y_tr_pred))\n",
    "\n",
    "        # Predict on test fold\n",
    "        y_te_pred = model.predict(X_te)\n",
    "        fold_test_mapes.append(mean_absolute_percentage_error(y_te, y_te_pred))\n",
    "\n",
    "    # Calculate mean & std for train/test MAPE across folds\n",
    "    train_mape_mean = np.mean(fold_train_mapes) * 100\n",
    "    train_mape_std  = np.std(fold_train_mapes)  * 100\n",
    "\n",
    "    test_mape_mean  = np.mean(fold_test_mapes)  * 100\n",
    "    test_mape_std   = np.std(fold_test_mapes)   * 100\n",
    "\n",
    "    return train_mape_mean, train_mape_std, test_mape_mean, test_mape_std"
   ],
   "id": "a3092d7c02558856"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dp = dataPipeline.DataPipeline()\n",
    "df = dp.runPipeline(\n",
    "    filePath=\"../data/immo_data_202208_v2.csv\",\n",
    "    imputer=None,\n",
    "    normalizeAndStandardize= False,\n",
    "    get_dummies = False\n",
    ")"
   ],
   "id": "a232e7befbeac3fb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#show all columns\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "id": "6efc83d197508a3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.head()",
   "id": "834dcf6054c1378b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.info()",
   "id": "7a2fa5bef86a11bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Categorical columns\n",
    "cat_col =[\"Availability\",\"type_unified\",\"region_group\"]"
   ],
   "id": "7120aff46e1dd68b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df[cat_col] = df[cat_col].astype('category')",
   "id": "5d96431cf8da8162"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df[cat_col].isna().sum()",
   "id": "ac86e3e48cf2ba2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.head()",
   "id": "738f68b14d40689f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.loc[df['Space extracted'] < 5, 'Space extracted'] = np.nan\n",
    "df.loc[df[\"Floor\"] >= 41, \"Floor\"] = np.nan\n",
    "\n",
    "#Filling Floor for House types with zeros\n",
    "house_types = [\n",
    "    'detached-house', 'villa', 'semi-detached-house', 'terrace-house',\n",
    "    'chalet', 'farmhouse', 'rustico', 'castle', 'detached-secondary-suite'\n",
    "]\n",
    "df.loc[\n",
    "    (df['type_unified'].isin(house_types)) & (df['Floor'].isna()),\n",
    "    'Floor'\n",
    "] = 0\n",
    "#Fill na with 0\n",
    "df[\"detail_responsive#surface_usable\"] = df[\"detail_responsive#surface_usable\"].fillna(0)\n",
    "df[\"Number of floors:\"] = df[\"Number of floors:\"].fillna(1)\n",
    "df[\"Plot_area_unified\"] = df[\"Plot_area_unified\"].fillna(0)"
   ],
   "id": "a073ae2285712499"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.head()",
   "id": "344fd9c86109b270"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#drop column Availability\n",
    "df = df.drop(columns=[\"Availability\"])"
   ],
   "id": "7090795be98c2b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define categorical and numerical columns\n",
    "cat_col = [\"type_unified\", \"region_group\"]\n",
    "num_col = [col for col in df.columns if col not in cat_col + [\"price_cleaned\"]]\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=5)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessors in a column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, num_col),\n",
    "        ('cat', categorical_transformer, cat_col)\n",
    "    ]\n",
    ")"
   ],
   "id": "4429f6a9f94da0f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Random Forest baseline model",
   "id": "45bf464c1f874e33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rf_baseline = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    criterion='squared_error',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=1.0,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=None,\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    ccp_alpha=0.0,\n",
    "    max_samples=None,\n",
    "    monotonic_cst=None\n",
    ")"
   ],
   "id": "641821eab9801c99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rf_estimater_10 = RandomForestRegressor(\n",
    "    n_estimators=10,\n",
    "    criterion='squared_error',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=1.0,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=None,\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    ccp_alpha=0.0,\n",
    "    max_samples=None,\n",
    "    monotonic_cst=None\n",
    ")"
   ],
   "id": "d103a0fa9906da63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create and combine preprocessing and modeling in a pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', rf_baseline)\n",
    "])\n",
    "\n",
    "# Separate target and features\n",
    "X = df.drop(columns=[\"price_cleaned\"])\n",
    "y = df[\"price_cleaned\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "pipeline.fit(X_train, y_train)"
   ],
   "id": "33f01157910128c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#caluclate mape on train data\n",
    "y_pred = pipeline.predict(X_train)\n",
    "r2, R2_adjusted, mape = calculate_metrics(X_train, y_train, y_pred)\n",
    "print(f\"R2 {r2},Adjusted R^2:{R2_adjusted}, MAPE:{mape}%\")"
   ],
   "id": "cb0180065c87f05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#caluclate mape on test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "r2, R2_adjusted, mape=calculate_metrics(X_train, y_test, y_pred)\n",
    "print(f\"R2 {r2},Adjusted R^2:{R2_adjusted}, MAPE:{mape}%\")"
   ],
   "id": "e3e28f394092e303"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameter tuning: Estimators",
   "id": "fb2f4e76a281af22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Suppose we have these\n",
    "estimators = [10, 20, 50, 70, 100, 200]\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_train_preprocessed = pd.DataFrame(X_train_preprocessed)\n",
    "\n",
    "\n",
    "train_mape_scores_mean = []\n",
    "train_mape_scores_std = []\n",
    "test_mape_scores_mean = []\n",
    "test_mape_scores_std = []"
   ],
   "id": "11768a02511dbcc2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for estimator in tqdm(estimators):\n",
    "    rf_estimator = RandomForestRegressor(\n",
    "        n_estimators=estimator,\n",
    "        criterion='squared_error',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    pipeline = Pipeline(steps=[('model', rf_estimator)])\n",
    "\n",
    "    # For storing MAPE per fold\n",
    "    fold_train_mapes = []\n",
    "    fold_test_mapes = []\n",
    "\n",
    "    # Manual CV loop\n",
    "    for train_idx, test_idx in cv.split(X_train_preprocessed):\n",
    "        X_tr, X_te = X_train_preprocessed.iloc[train_idx], X_train_preprocessed.iloc[test_idx]\n",
    "        y_tr, y_te = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        pipeline.fit(X_tr, y_tr)\n",
    "\n",
    "        # Predict on training fold\n",
    "        y_tr_pred = pipeline.predict(X_tr)\n",
    "        fold_train_mapes.append(mean_absolute_percentage_error(y_tr, y_tr_pred))\n",
    "\n",
    "        # Predict on test fold\n",
    "        y_te_pred = pipeline.predict(X_te)\n",
    "        fold_test_mapes.append(mean_absolute_percentage_error(y_te, y_te_pred))\n",
    "\n",
    "    # Average across folds\n",
    "    train_mape_mean = np.mean(fold_train_mapes) * 100\n",
    "    train_mape_std = np.std(fold_train_mapes) * 100\n",
    "\n",
    "    test_mape_mean = np.mean(fold_test_mapes) * 100\n",
    "    test_mape_std = np.std(fold_test_mapes) * 100\n",
    "\n",
    "    # Store results\n",
    "    train_mape_scores_mean.append(train_mape_mean)\n",
    "    train_mape_scores_std.append(train_mape_std)\n",
    "    test_mape_scores_mean.append(test_mape_mean)\n",
    "    test_mape_scores_std.append(test_mape_std)\n",
    "\n",
    "    print(\n",
    "        f\"Estimator: {estimator}, \"\n",
    "        f\"Train MAPE: {train_mape_mean:.2f}% (±{train_mape_std:.2f}), \"\n",
    "        f\"Test MAPE: {test_mape_mean:.2f}% (±{test_mape_std:.2f})\"\n",
    "    )"
   ],
   "id": "4faa7e69268b20f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot the MAPE scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.errorbar(estimators, train_mape_scores_mean, yerr=train_mape_scores_std, label='Train MAPE', marker='o', capsize=5)\n",
    "plt.errorbar(estimators, test_mape_scores_mean, yerr=test_mape_scores_std, label='Test MAPE', marker='o', capsize=5)\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('MAPE (%)')\n",
    "plt.title('Train vs Test MAPE Scores for Random Forest')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "c4c5a13b6d448b21"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameter tuning: Max Depth",
   "id": "b82862525d9233f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Suppose we have these\n",
    "depths = [7, 10, 15, 20, 25, 30, 35]\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_train_preprocessed = pd.DataFrame(X_train_preprocessed)\n",
    "\n",
    "train_mape_scores_mean = []\n",
    "train_mape_scores_std = []\n",
    "test_mape_scores_mean = []\n",
    "test_mape_scores_std = []\n",
    "for depth in tqdm(depths):\n",
    "    rf_estimator = RandomForestRegressor(\n",
    "        n_estimators=70,\n",
    "        max_depth=depth,\n",
    "        criterion='squared_error',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    pipeline = Pipeline(steps=[('model', rf_estimator)])\n",
    "\n",
    "    # For storing MAPE per fold\n",
    "    fold_train_mapes = []\n",
    "    fold_test_mapes = []\n",
    "\n",
    "    # Manual CV loop\n",
    "    for train_idx, test_idx in cv.split(X_train_preprocessed):\n",
    "        X_tr, X_te = X_train_preprocessed.iloc[train_idx], X_train_preprocessed.iloc[test_idx]\n",
    "        y_tr, y_te = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "\n",
    "        pipeline.fit(X_tr, y_tr)\n",
    "\n",
    "        # Predict on training fold\n",
    "        y_tr_pred = pipeline.predict(X_tr)\n",
    "        fold_train_mapes.append(mean_absolute_percentage_error(y_tr, y_tr_pred))\n",
    "\n",
    "        # Predict on test fold\n",
    "        y_te_pred = pipeline.predict(X_te)\n",
    "        fold_test_mapes.append(mean_absolute_percentage_error(y_te, y_te_pred))\n",
    "\n",
    "    # Average across folds\n",
    "    train_mape_mean = np.mean(fold_train_mapes) * 100\n",
    "    train_mape_std = np.std(fold_train_mapes) * 100\n",
    "\n",
    "    test_mape_mean = np.mean(fold_test_mapes) * 100\n",
    "    test_mape_std = np.std(fold_test_mapes) * 100\n",
    "\n",
    "    # Store results\n",
    "    train_mape_scores_mean.append(train_mape_mean)\n",
    "    train_mape_scores_std.append(train_mape_std)\n",
    "    test_mape_scores_mean.append(test_mape_mean)\n",
    "    test_mape_scores_std.append(test_mape_std)\n",
    "\n",
    "    print(\n",
    "        f\"Estimator: {depth}, \"\n",
    "        f\"Train MAPE: {train_mape_mean:.2f}% (±{train_mape_std:.2f}), \"\n",
    "        f\"Test MAPE: {test_mape_mean:.2f}% (±{test_mape_std:.2f})\"\n",
    "    )"
   ],
   "id": "8ab65db89d034ceb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot the MAPE scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.errorbar(depths, train_mape_scores_mean, yerr=train_mape_scores_std, label='Train MAPE', marker='o', capsize=5)\n",
    "plt.errorbar(depths, test_mape_scores_mean, yerr=test_mape_scores_std, label='Test MAPE', marker='o', capsize=5)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('MAPE (%)')\n",
    "plt.title('Train vs Test MAPE Scores for Random Forest')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "cd84e03e5767c726"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameter tuning: Min Samples Split",
   "id": "c74d80923e523431"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "min_samples_splits  = [2, 3, 4, 5]\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_train_preprocessed = pd.DataFrame(X_train_preprocessed)\n",
    "\n",
    "# Prepare lists to store results\n",
    "train_mape_scores_mean = []\n",
    "train_mape_scores_std = []\n",
    "test_mape_scores_mean = []\n",
    "test_mape_scores_std = []\n",
    "\n",
    "# Loop over different depths\n",
    "for split in tqdm(min_samples_splits):\n",
    "    # Define your estimator with the current max_depth\n",
    "    rf_estimator = RandomForestRegressor(\n",
    "        n_estimators=70,\n",
    "        max_depth=25,\n",
    "        min_samples_split=split,\n",
    "        criterion='squared_error',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Build a Pipeline (you can add more steps if needed)\n",
    "    pipeline = Pipeline(steps=[('model', rf_estimator)])\n",
    "\n",
    "    # Call the function to perform manual CV and get MAPE metrics\n",
    "    train_mape_mean, train_mape_std, test_mape_mean, test_mape_std = manual_cv_score(\n",
    "        X=X_train_preprocessed,\n",
    "        y=y_train,\n",
    "        cv=cv,\n",
    "        model=pipeline\n",
    "    )\n",
    "\n",
    "    # Store results\n",
    "    train_mape_scores_mean.append(train_mape_mean)\n",
    "    train_mape_scores_std.append(train_mape_std)\n",
    "    test_mape_scores_mean.append(test_mape_mean)\n",
    "    test_mape_scores_std.append(test_mape_std)\n",
    "\n",
    "    # Print progress\n",
    "    print(\n",
    "        f\"Max split: {split}, \"\n",
    "        f\"Train MAPE: {train_mape_mean:.2f}% (±{train_mape_std:.2f}), \"\n",
    "        f\"Test MAPE: {test_mape_mean:.2f}% (±{test_mape_std:.2f})\"\n",
    "    )"
   ],
   "id": "8670c35430c2fcc6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot the MAPE scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.errorbar(depths, train_mape_scores_mean, yerr=train_mape_scores_std, label='Train MAPE', marker='o', capsize=5)\n",
    "plt.errorbar(depths, test_mape_scores_mean, yerr=test_mape_scores_std, label='Test MAPE', marker='o', capsize=5)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('MAPE (%)')\n",
    "plt.title('Train vs Test MAPE Scores for Random Forest')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "67e4850afdb03f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameter tuning: Max Features\n",
   "id": "abe302b7f19466e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "max_features = [1.0, 0.5, 0.3, 'sqrt', 'log2']\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_train_preprocessed = pd.DataFrame(X_train_preprocessed)\n",
    "\n",
    "# Prepare lists to store results\n",
    "train_mape_scores_mean = []\n",
    "train_mape_scores_std = []\n",
    "test_mape_scores_mean = []\n",
    "test_mape_scores_std = []\n",
    "\n",
    "# Loop over different depths\n",
    "for feature in tqdm(max_features):\n",
    "    # Define your estimator with the current max_depth\n",
    "    rf_estimator = RandomForestRegressor(\n",
    "        n_estimators=70,\n",
    "        max_depth=25,\n",
    "        min_samples_split=2,\n",
    "        max_features=feature,\n",
    "        criterion='squared_error',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Build a Pipeline (you can add more steps if needed)\n",
    "    pipeline = Pipeline(steps=[('model', rf_estimator)])\n",
    "\n",
    "    # Call the function to perform manual CV and get MAPE metrics\n",
    "    train_mape_mean, train_mape_std, test_mape_mean, test_mape_std = manual_cv_score(\n",
    "        X=X_train_preprocessed,\n",
    "        y=y_train,\n",
    "        cv=cv,\n",
    "        model=pipeline\n",
    "    )\n",
    "\n",
    "    # Store results\n",
    "    train_mape_scores_mean.append(train_mape_mean)\n",
    "    train_mape_scores_std.append(train_mape_std)\n",
    "    test_mape_scores_mean.append(test_mape_mean)\n",
    "    test_mape_scores_std.append(test_mape_std)\n",
    "\n",
    "    # Print progress\n",
    "    print(\n",
    "        f\"Max features: {feature}, \"\n",
    "        f\"Train MAPE: {train_mape_mean:.2f}% (±{train_mape_std:.2f}), \"\n",
    "        f\"Test MAPE: {test_mape_mean:.2f}% (±{test_mape_std:.2f})\"\n",
    "    )\n"
   ],
   "id": "b3f2077fff8b5ff5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot the MAPE scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.errorbar(feature, train_mape_scores_mean, yerr=train_mape_scores_std, label='Train MAPE', marker='o', capsize=5)\n",
    "plt.errorbar(feature, test_mape_scores_mean, yerr=test_mape_scores_std, label='Test MAPE', marker='o', capsize=5)\n",
    "plt.xlabel('Max Features')\n",
    "plt.ylabel('MAPE (%)')\n",
    "plt.title('Train vs Test MAPE Scores for Random Forest')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "ff5c60dda7824b63"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameter tuning: Min Samples Leaf",
   "id": "e75bbf75127f8494"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "min_samples_leafs = [1, 2, 3, 4, 5]\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Prepare lists to store results\n",
    "train_mape_scores_mean = []\n",
    "train_mape_scores_std = []\n",
    "test_mape_scores_mean = []\n",
    "test_mape_scores_std = []\n",
    "\n",
    "# Loop over different depths\n",
    "for leafs in tqdm(min_samples_leafs):\n",
    "    # Define your estimator with the current max_depth\n",
    "    rf_estimator = RandomForestRegressor(\n",
    "        n_estimators=70,\n",
    "        max_depth=25,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=leafs,\n",
    "        max_features=1,\n",
    "        criterion='squared_error',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Build a Pipeline (you can add more steps if needed)\n",
    "    pipeline = Pipeline(steps=[('model', rf_estimator)])\n",
    "\n",
    "    # Call the function to perform manual CV and get MAPE metrics\n",
    "    train_mape_mean, train_mape_std, test_mape_mean, test_mape_std = manual_cv_score(\n",
    "        X=X_train_preprocessed,\n",
    "        y=y_train,\n",
    "        cv=cv,\n",
    "        model=pipeline\n",
    "    )\n",
    "\n",
    "    # Store results\n",
    "    train_mape_scores_mean.append(train_mape_mean)\n",
    "    train_mape_scores_std.append(train_mape_std)\n",
    "    test_mape_scores_mean.append(test_mape_mean)\n",
    "    test_mape_scores_std.append(test_mape_std)\n",
    "\n",
    "    # Print progress\n",
    "    print(\n",
    "        f\"Max leafs: {leafs}, \"\n",
    "        f\"Train MAPE: {train_mape_mean:.2f}% (±{train_mape_std:.2f}), \"\n",
    "        f\"Test MAPE: {test_mape_mean:.2f}% (±{test_mape_std:.2f})\"\n",
    "    )"
   ],
   "id": "e613409888761a04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot the MAPE scores\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.errorbar(leafs, train_mape_scores_mean, yerr=train_mape_scores_std, label='Train MAPE', marker='o', capsize=5)\n",
    "plt.errorbar(leafs, test_mape_scores_mean, yerr=test_mape_scores_std, label='Test MAPE', marker='o', capsize=5)\n",
    "plt.xlabel('Max Features')\n",
    "plt.ylabel('MAPE (%)')\n",
    "plt.title('Train vs Test MAPE Scores for Random Forest')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "id": "b98d9d4d6f64f9c3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
