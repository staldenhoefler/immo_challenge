{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-29T16:40:49.803289Z",
     "start_time": "2024-12-29T16:40:49.793215Z"
    }
   },
   "source": [
    "import src.dataPipeline as dataPipeline\n",
    "import importlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import optuna\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "# Evaluating the model\n",
    "from sklearn.metrics import mean_absolute_percentage_error,r2_score ,make_scorer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "importlib.reload(dataPipeline)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.dataPipeline' from 'C:\\\\Users\\\\wartm\\\\Documents\\\\FHNW\\\\immo_challenge\\\\src\\\\dataPipeline.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:40:54.784971Z",
     "start_time": "2024-12-29T16:40:49.809296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dp = dataPipeline.DataPipeline()\n",
    "df = dp.runPipeline(\n",
    "    filePath=\"../data/immo_data_202208_v2.csv\",\n",
    "    imputer=None,\n",
    "    normalizeAndStandardize= False,\n",
    "    basic_house_imputer = True,\n",
    "    get_dummies = False\n",
    ")"
   ],
   "id": "7737ec9c3fa88ffa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wartm\\Documents\\FHNW\\immo_challenge\\src\\dataPipeline.py:44: DtypeWarning: Columns (3,4,5,6,11,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,45,46,47,49,50,107,110,114,115,116,119,120,121,124,125,126,128,131,132) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.data = pd.read_csv(filePath)\n",
      "C:\\Users\\wartm\\Documents\\FHNW\\immo_challenge\\src\\dataPipeline.py:71: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ]].bfill(axis=1)['Space extracted']\n",
      "C:\\Users\\wartm\\Documents\\FHNW\\immo_challenge\\src\\dataPipeline.py:76: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ]].bfill(axis=1)['Plot_area_unified']\n",
      "C:\\Users\\wartm\\Documents\\FHNW\\immo_challenge\\src\\dataPipeline.py:82: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ]].bfill(axis=1)['Availability']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:40:54.928319Z",
     "start_time": "2024-12-29T16:40:54.886350Z"
    }
   },
   "cell_type": "code",
   "source": "df.head()",
   "id": "72d59aea221ccb17",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Availability  Floor  detail_responsive#surface_usable  Floor_space_merged  \\\n",
       "0   On request    4.0                               NaN                 NaN   \n",
       "1   On request    NaN                               NaN               242.0   \n",
       "2  Immediately    2.0                               NaN                 NaN   \n",
       "3   On request    NaN                               NaN               257.0   \n",
       "4   On request    0.0                               NaN                 NaN   \n",
       "\n",
       "   ForestDensityL  ForestDensityM  ForestDensityS  NoisePollutionRailwayL  \\\n",
       "0        0.511176        0.286451        0.090908                     0.0   \n",
       "1        0.511176        0.286451        0.090908                     0.0   \n",
       "2        0.163362        0.095877        0.001911                     0.0   \n",
       "3        0.511176        0.286451        0.090908                     0.0   \n",
       "4        0.333865        0.279276        0.145835                     0.0   \n",
       "\n",
       "   NoisePollutionRailwayM  NoisePollutionRailwayS  ...  gde_workers_total  \\\n",
       "0                     0.0                     0.0  ...              331.0   \n",
       "1                     0.0                     0.0  ...              331.0   \n",
       "2                     0.0                     0.0  ...            33493.0   \n",
       "3                     0.0                     0.0  ...              331.0   \n",
       "4                     0.0                     0.0  ...             1355.0   \n",
       "\n",
       "   price_cleaned  Space extracted    type_unified  Plot_area_unified  \\\n",
       "0      1150000.0            100.0       penthouse                NaN   \n",
       "1      1420000.0            156.0   terrace-house              222.0   \n",
       "2       720000.0             93.0       penthouse                NaN   \n",
       "3      1430000.0            154.0  detached-house              370.0   \n",
       "4       995000.0            142.0            flat                NaN   \n",
       "\n",
       "   No. of rooms:  Last refurbishment:  Year built:  Number of floors:  \\\n",
       "0            5.0                  NaN          NaN                NaN   \n",
       "1            5.0                  NaN          NaN                NaN   \n",
       "2            5.0                  NaN          NaN                NaN   \n",
       "3            5.0                  NaN          NaN                NaN   \n",
       "4            5.0                  NaN          NaN                NaN   \n",
       "\n",
       "   region_group  \n",
       "0          11.0  \n",
       "1          11.0  \n",
       "2          11.0  \n",
       "3          11.0  \n",
       "4          11.0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Availability</th>\n",
       "      <th>Floor</th>\n",
       "      <th>detail_responsive#surface_usable</th>\n",
       "      <th>Floor_space_merged</th>\n",
       "      <th>ForestDensityL</th>\n",
       "      <th>ForestDensityM</th>\n",
       "      <th>ForestDensityS</th>\n",
       "      <th>NoisePollutionRailwayL</th>\n",
       "      <th>NoisePollutionRailwayM</th>\n",
       "      <th>NoisePollutionRailwayS</th>\n",
       "      <th>...</th>\n",
       "      <th>gde_workers_total</th>\n",
       "      <th>price_cleaned</th>\n",
       "      <th>Space extracted</th>\n",
       "      <th>type_unified</th>\n",
       "      <th>Plot_area_unified</th>\n",
       "      <th>No. of rooms:</th>\n",
       "      <th>Last refurbishment:</th>\n",
       "      <th>Year built:</th>\n",
       "      <th>Number of floors:</th>\n",
       "      <th>region_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On request</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511176</td>\n",
       "      <td>0.286451</td>\n",
       "      <td>0.090908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>1150000.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>penthouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On request</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>242.0</td>\n",
       "      <td>0.511176</td>\n",
       "      <td>0.286451</td>\n",
       "      <td>0.090908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>1420000.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>terrace-house</td>\n",
       "      <td>222.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Immediately</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.163362</td>\n",
       "      <td>0.095877</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33493.0</td>\n",
       "      <td>720000.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>penthouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On request</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>257.0</td>\n",
       "      <td>0.511176</td>\n",
       "      <td>0.286451</td>\n",
       "      <td>0.090908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>1430000.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>detached-house</td>\n",
       "      <td>370.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On request</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333865</td>\n",
       "      <td>0.279276</td>\n",
       "      <td>0.145835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1355.0</td>\n",
       "      <td>995000.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>flat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:40:55.112893Z",
     "start_time": "2024-12-29T16:40:55.095763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df[\"region_group\"] = df[\"region_group\"].astype(\"category\")\n",
    "df[\"type_unified\"] = df[\"type_unified\"].astype(\"category\")\n",
    "df[\"Availability\"] = df[\"Availability\"].astype(\"category\")"
   ],
   "id": "ccbfca3e58a49ee4",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:40:55.310214Z",
     "start_time": "2024-12-29T16:40:55.295546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = df.drop(\"price_cleaned\", axis=1)\n",
    "y = df[\"price_cleaned\"]"
   ],
   "id": "532256eaa024fd9",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:42:12.591801Z",
     "start_time": "2024-12-29T16:40:55.567459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Kategorische und numerische Spalten definieren\n",
    "cat_col = ['region_group', 'type_unified', 'Availability']\n",
    "numerical_features = [col for col in df.columns if col not in cat_col + [\"price_cleaned\"]]\n",
    "\n",
    "# Preprocessing für numerische Daten\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=5)),  # Fehlwerte auffüllen\n",
    "    ('scaler', StandardScaler())  # Standardisieren\n",
    "])\n",
    "\n",
    "# Preprocessing für kategorische Daten\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-Hot-Encoding\n",
    "])\n",
    "\n",
    "# ColumnTransformer erstellen\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, cat_col)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline nur für das Preprocessing erstellen\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "\n",
    "X_train_transformed = pipeline.fit_transform(X_train)\n",
    "X_test_transformed = pipeline.transform(X_test)"
   ],
   "id": "a3434603fde42af9",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:59:52.991919Z",
     "start_time": "2024-12-29T16:51:15.280813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 1.0, log=True)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "\n",
    "    # Create the base estimator\n",
    "    base_estimator = DecisionTreeRegressor(max_depth=max_depth)\n",
    "\n",
    "    # Create AdaBoostRegressor with the suggested hyperparameters\n",
    "    model = AdaBoostRegressor(\n",
    "        estimator=base_estimator,  # Changed from base_estimator to estimator\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "\n",
    "    # Use K-Fold Cross Validation if dataset is large enough, otherwise use train-test split\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mape_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train_transformed):\n",
    "        X_train_fold, X_val_fold = X_train_transformed[train_index], X_train_transformed[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Predict on the validation fold\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "\n",
    "        # Evaluate the model using Mean Absolute Percentage Error\n",
    "        mape = mean_absolute_percentage_error(y_val_fold, y_pred)\n",
    "        mape_scores.append(mape)\n",
    "\n",
    "    return sum(mape_scores) / len(mape_scores)\n",
    "\n",
    "# Create a study and optimize the objective function\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10, timeout=120)\n",
    "\n",
    "# Output the best hyperparameters and score\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(\"Best MAPE:\", study.best_value)"
   ],
   "id": "e55c61cdb3fa93a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 17:51:15,296] A new study created in memory with name: no-name-af8f11f4-1105-4e33-af38-751b1519132c\n",
      "[I 2024-12-29 17:53:42,413] Trial 0 finished with value: 1.5386483105586333 and parameters: {'n_estimators': 241, 'learning_rate': 0.035909310460729746, 'max_depth': 2}. Best is trial 0 with value: 1.5386483105586333.\n",
      "[I 2024-12-29 17:59:52,986] Trial 1 finished with value: 0.5504078064945181 and parameters: {'n_estimators': 248, 'learning_rate': 0.5187635838081097, 'max_depth': 10}. Best is trial 1 with value: 0.5504078064945181.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 248, 'learning_rate': 0.5187635838081097, 'max_depth': 10}\n",
      "Best MAPE: 0.5504078064945181\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T16:51:10.314266300Z",
     "start_time": "2024-12-29T16:12:21.065714Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 17:12:21,065] A new study created in memory with name: no-name-c5d7ded9-1765-4eb3-b24d-b429d63a09c7\n",
      "[I 2024-12-29 17:13:19,050] Trial 0 finished with value: 5.4784900723243855 and parameters: {'n_estimators': 461, 'learning_rate': 0.5639378541596162, 'max_depth': 1}. Best is trial 0 with value: 5.4784900723243855.\n",
      "[I 2024-12-29 17:29:06,341] Trial 1 finished with value: 0.569172827491238 and parameters: {'n_estimators': 498, 'learning_rate': 0.38558802221495375, 'max_depth': 10}. Best is trial 1 with value: 0.569172827491238.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 498, 'learning_rate': 0.38558802221495375, 'max_depth': 10}\n",
      "Best MAPE: 0.569172827491238\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "AdaBoostRegressor.__init__() got an unexpected keyword argument 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 50\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# Train the best model with the optimal parameters\u001B[39;00m\n\u001B[0;32m     49\u001B[0m best_params \u001B[38;5;241m=\u001B[39m study\u001B[38;5;241m.\u001B[39mbest_params\n\u001B[1;32m---> 50\u001B[0m best_model \u001B[38;5;241m=\u001B[39m \u001B[43mAdaBoostRegressor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDecisionTreeRegressor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_depth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbest_params\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax_depth\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_estimators\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbest_params\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn_estimators\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbest_params\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlearning_rate\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m42\u001B[39;49m\n\u001B[0;32m     55\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m best_model\u001B[38;5;241m.\u001B[39mfit(X_train_transformed, y_train)\n\u001B[0;32m     58\u001B[0m \u001B[38;5;66;03m# Evaluate the final model\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: AdaBoostRegressor.__init__() got an unexpected keyword argument 'base_estimator'"
     ]
    }
   ],
   "execution_count": 28,
   "source": [
    "# Train the best model with the optimal parameters\n",
    "best_params = study.best_params\n",
    "best_model = AdaBoostRegressor(\n",
    "    base_estimator=DecisionTreeRegressor(max_depth=best_params[\"max_depth\"]),\n",
    "    n_estimators=best_params[\"n_estimators\"],\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    random_state=42\n",
    ")\n",
    "best_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Evaluate the final model\n",
    "final_mape = mean_absolute_percentage_error(y_test, best_model.predict(X_test_transformed))\n",
    "print(\"Final MAPE with the best model:\", final_mape)"
   ],
   "id": "af6a3fb8302d24f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Price logaritmiert",
   "id": "a020f2049f01b01a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:00:20.506606Z",
     "start_time": "2024-12-29T17:00:20.496856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_test_log = np.log(y_test)\n",
    "y_train_log = np.log(y_train)"
   ],
   "id": "8dd828b44f3f7829",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:02:47.669568Z",
     "start_time": "2024-12-29T17:00:32.645832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 1.0, log=True)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "\n",
    "    # Create the base estimator\n",
    "    base_estimator = DecisionTreeRegressor(max_depth=max_depth)\n",
    "\n",
    "    # Create AdaBoostRegressor with the suggested hyperparameters\n",
    "    model = AdaBoostRegressor(\n",
    "        estimator=base_estimator,  # Changed from base_estimator to estimator\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "\n",
    "    # Use K-Fold Cross Validation if dataset is large enough, otherwise use train-test split\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mape_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train_transformed):\n",
    "        X_train_fold, X_val_fold = X_train_transformed[train_index], X_train_transformed[val_index]\n",
    "        y_train_fold, y_val_fold = y_train_log.iloc[train_index], y_train_log.iloc[val_index]\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Predict on the validation fold\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "\n",
    "        # Evaluate the model using Mean Absolute Percentage Error\n",
    "        mape = mean_absolute_percentage_error(np.exp(y_val_fold), np.exp(y_pred))\n",
    "        mape_scores.append(mape)\n",
    "\n",
    "    return sum(mape_scores) / len(mape_scores)\n",
    "\n",
    "# Create a study and optimize the objective function\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20, timeout=120)\n",
    "\n",
    "# Output the best hyperparameters and score\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(\"Best MAPE:\", study.best_value)\n"
   ],
   "id": "6ab3c41c70ed1a99",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 18:00:32,645] A new study created in memory with name: no-name-56aa84c8-0840-4c29-9d5e-335e813f03e3\n",
      "[I 2024-12-29 18:01:16,822] Trial 0 finished with value: 0.46127282240777784 and parameters: {'n_estimators': 74, 'learning_rate': 0.05019823607946922, 'max_depth': 2}. Best is trial 0 with value: 0.46127282240777784.\n",
      "[I 2024-12-29 18:02:47,663] Trial 1 finished with value: 0.4742881910186676 and parameters: {'n_estimators': 300, 'learning_rate': 0.803613511388423, 'max_depth': 2}. Best is trial 0 with value: 0.46127282240777784.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 74, 'learning_rate': 0.05019823607946922, 'max_depth': 2}\n",
      "Best MAPE: 0.46127282240777784\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:05:23.205659Z",
     "start_time": "2024-12-29T17:05:10.402599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the best model with the optimal parameters\n",
    "best_params = study.best_params\n",
    "best_model = AdaBoostRegressor(\n",
    "    estimator=DecisionTreeRegressor(max_depth=best_params[\"max_depth\"]),\n",
    "    n_estimators=best_params[\"n_estimators\"],\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    random_state=42\n",
    ")\n",
    "best_model.fit(X_train_transformed, y_train_log)\n",
    "\n",
    "# Evaluate the final model\n",
    "final_mape = mean_absolute_percentage_error(y_test, np.exp(best_model.predict(X_test_transformed)))\n",
    "print(\"Final MAPE with the best model:\", final_mape)\n"
   ],
   "id": "2f8a580a415a10d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MAPE with the best model: 0.45984305946082693\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Mehr Hyperparameter",
   "id": "6fa4beeca3f6e76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:43:01.456703Z",
     "start_time": "2024-12-29T17:37:13.361309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 1000)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 1.0, log=True)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 20)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 20)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
    "\n",
    "    # Create the base estimator\n",
    "    base_estimator = DecisionTreeRegressor(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features\n",
    "    )\n",
    "\n",
    "    # Create AdaBoostRegressor\n",
    "    model = AdaBoostRegressor(\n",
    "        estimator=base_estimator,\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "\n",
    "    # Use K-Fold Cross Validation if dataset is large enough, otherwise use train-test split\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mape_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train_transformed):\n",
    "        X_train_fold, X_val_fold = X_train_transformed[train_index], X_train_transformed[val_index]\n",
    "        y_train_fold, y_val_fold = y_train_log.iloc[train_index], y_train_log.iloc[val_index]\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Predict on the validation fold\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "\n",
    "        # Evaluate the model using Mean Absolute Percentage Error\n",
    "        mape = mean_absolute_percentage_error(np.exp(y_val_fold), np.exp(y_pred))\n",
    "        mape_scores.append(mape)\n",
    "\n",
    "    return sum(mape_scores) / len(mape_scores)\n",
    "\n",
    "# Create a study and optimize the objective function\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20, timeout=180)\n",
    "\n",
    "# Output the best hyperparameters and score\n",
    "print(\"Best parameters:\", study.best_params)\n",
    "print(\"Best MAPE:\", study.best_value)\n"
   ],
   "id": "3b059a09f5e5eae5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 18:37:13,361] A new study created in memory with name: no-name-b057ba57-bafb-4b70-b7e2-423ec6736390\n",
      "[I 2024-12-29 18:40:03,554] Trial 0 finished with value: 0.5118593385987135 and parameters: {'n_estimators': 258, 'learning_rate': 0.0019831691403489203, 'max_depth': 2, 'min_samples_split': 16, 'min_samples_leaf': 13, 'max_features': None}. Best is trial 0 with value: 0.5118593385987135.\n",
      "[I 2024-12-29 18:43:01,444] Trial 1 finished with value: 0.4119995156537217 and parameters: {'n_estimators': 780, 'learning_rate': 0.00287603911878279, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.4119995156537217.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 780, 'learning_rate': 0.00287603911878279, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 9, 'max_features': 'sqrt'}\n",
      "Best MAPE: 0.4119995156537217\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Kaggle Wetbewerb",
   "id": "a060b401b3b20c45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:07:46.080892Z",
     "start_time": "2024-12-29T17:07:40.842974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_kaggle = dp.prepare_kaggle_dataset(\n",
    "    filePath=\"../data/test_data-Kaggle-v0.11.csv\",\n",
    "    imputer=None,\n",
    "    normalizeAndStandardize=False,\n",
    "    basic_house_imputer=True,\n",
    "    get_dummies=False\n",
    ")\n",
    "df_kaggle.head()"
   ],
   "id": "4876003b1a50e855",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wartm\\Documents\\FHNW\\immo_challenge\\src\\dataPipeline.py:44: DtypeWarning: Columns (3,4,5,6,11,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,45,46,48,49,104,111,112,115,116,117,120,121,122,124,127,128,130,131) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.data = pd.read_csv(filePath)\n",
      "C:\\Users\\wartm\\Documents\\FHNW\\immo_challenge\\src\\dataPipeline.py:71: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ]].bfill(axis=1)['Space extracted']\n",
      "C:\\Users\\wartm\\Documents\\FHNW\\immo_challenge\\src\\dataPipeline.py:76: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ]].bfill(axis=1)['Plot_area_unified']\n",
      "C:\\Users\\wartm\\Documents\\FHNW\\immo_challenge\\src\\dataPipeline.py:82: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ]].bfill(axis=1)['Availability']\n",
      "C:\\Users\\wartm\\Documents\\FHNW\\immo_challenge\\src\\dataPipeline.py:137: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[mask, 'plz_parsed'] = df.loc[mask, 'address'].apply(extractPlz)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in column: Type:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  Availability  Floor  detail_responsive#surface_usable  Floor_space_merged  \\\n",
       "0   On request    0.0                               0.0                 NaN   \n",
       "1   On request    0.0                               0.0                 NaN   \n",
       "2   On request    NaN                               0.0                 NaN   \n",
       "3  Immediately    0.0                               0.0               140.0   \n",
       "4   On request    0.0                               0.0               242.0   \n",
       "\n",
       "   ForestDensityL  ForestDensityM  ForestDensityS  NoisePollutionRailwayL  \\\n",
       "0        0.164382        0.100030        0.063548                0.003811   \n",
       "1        0.260855        0.170434        0.083253                0.002623   \n",
       "2        0.434114        0.357984        0.125505                0.000000   \n",
       "3        0.148190        0.076610        0.000000                0.005193   \n",
       "4        0.511176        0.286451        0.090908                0.000000   \n",
       "\n",
       "   NoisePollutionRailwayM  NoisePollutionRailwayS  ...  Space extracted  \\\n",
       "0                     0.0                     0.0  ...            220.0   \n",
       "1                     0.0                     0.0  ...            230.0   \n",
       "2                     0.0                     0.0  ...            131.0   \n",
       "3                     0.0                     0.0  ...            140.0   \n",
       "4                     0.0                     0.0  ...            156.0   \n",
       "\n",
       "     type_unified  Plot_area_unified  No. of rooms:  Last refurbishment:  \\\n",
       "0           villa              733.0            5.0                  NaN   \n",
       "1  detached-house              702.0            5.0                  NaN   \n",
       "2   stepped-house                0.0            5.0                  NaN   \n",
       "3   terrace-house              206.0            5.0                  NaN   \n",
       "4   terrace-house              222.0            5.0                  NaN   \n",
       "\n",
       "   Year built:  Number of floors:  Type:  Hall height:  region_group  \n",
       "0          NaN                1.0    NaN           NaN            11  \n",
       "1          NaN                1.0    NaN           NaN            11  \n",
       "2          NaN                1.0    NaN           NaN            11  \n",
       "3          NaN                1.0    NaN           NaN            11  \n",
       "4          NaN                1.0    NaN           NaN            11  \n",
       "\n",
       "[5 rows x 60 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Availability</th>\n",
       "      <th>Floor</th>\n",
       "      <th>detail_responsive#surface_usable</th>\n",
       "      <th>Floor_space_merged</th>\n",
       "      <th>ForestDensityL</th>\n",
       "      <th>ForestDensityM</th>\n",
       "      <th>ForestDensityS</th>\n",
       "      <th>NoisePollutionRailwayL</th>\n",
       "      <th>NoisePollutionRailwayM</th>\n",
       "      <th>NoisePollutionRailwayS</th>\n",
       "      <th>...</th>\n",
       "      <th>Space extracted</th>\n",
       "      <th>type_unified</th>\n",
       "      <th>Plot_area_unified</th>\n",
       "      <th>No. of rooms:</th>\n",
       "      <th>Last refurbishment:</th>\n",
       "      <th>Year built:</th>\n",
       "      <th>Number of floors:</th>\n",
       "      <th>Type:</th>\n",
       "      <th>Hall height:</th>\n",
       "      <th>region_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On request</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.164382</td>\n",
       "      <td>0.100030</td>\n",
       "      <td>0.063548</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>220.0</td>\n",
       "      <td>villa</td>\n",
       "      <td>733.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On request</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.260855</td>\n",
       "      <td>0.170434</td>\n",
       "      <td>0.083253</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>230.0</td>\n",
       "      <td>detached-house</td>\n",
       "      <td>702.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On request</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.434114</td>\n",
       "      <td>0.357984</td>\n",
       "      <td>0.125505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>131.0</td>\n",
       "      <td>stepped-house</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Immediately</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.148190</td>\n",
       "      <td>0.076610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>terrace-house</td>\n",
       "      <td>206.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On request</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>0.511176</td>\n",
       "      <td>0.286451</td>\n",
       "      <td>0.090908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>156.0</td>\n",
       "      <td>terrace-house</td>\n",
       "      <td>222.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:09:09.741506Z",
     "start_time": "2024-12-29T17:09:09.724358Z"
    }
   },
   "cell_type": "code",
   "source": "df_kaggle = df_kaggle.drop(['Type:', 'Hall height:'], axis=1)",
   "id": "a4727c8a83139058",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:09:10.522553Z",
     "start_time": "2024-12-29T17:09:10.511305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_kaggle[\"region_group\"] = df_kaggle[\"region_group\"].astype(\"category\")\n",
    "df_kaggle[\"type_unified\"] = df_kaggle[\"type_unified\"].astype(\"category\")\n",
    "df_kaggle[\"Availability\"] = df_kaggle[\"Availability\"].astype(\"category\")"
   ],
   "id": "e01a57f8e73734bc",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:10:26.090103Z",
     "start_time": "2024-12-29T17:09:11.134118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_kaggle = df_kaggle\n",
    "X_kaggle_transformed = pipeline.transform(X_kaggle)"
   ],
   "id": "844f33bc44b463cf",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-29T17:10:37.182087Z",
     "start_time": "2024-12-29T17:10:33.888265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.utils.helperFunctions import create_kaggle_results\n",
    "\n",
    "results = best_model.predict(X_kaggle_transformed)\n",
    "results = np.exp(results)\n",
    "create_kaggle_results(results, path_to_kaggledata=\"../data/test_data-Kaggle-v0.11.csv\", csv_name='adaboost_log_price.csv')"
   ],
   "id": "5570884b1e4893ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File adaboost_log_price.csv_2024-12-29_18-10-37.csv created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wartm\\Documents\\FHNW\\immo_challenge\\src\\utils\\helperFunctions.py:13: DtypeWarning: Columns (3,4,5,6,11,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,45,46,48,49,104,111,112,115,116,117,120,121,122,124,127,128,130,131) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  indexes = pd.read_csv(path_to_kaggledata)['Unnamed: 0']\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e2d09e12bc817c25"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
