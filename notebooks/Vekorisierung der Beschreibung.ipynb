{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-02T09:03:22.263943500Z",
     "start_time": "2024-12-02T09:03:14.700435200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\FHNW_Programmiersachen\\5_Sem\\immo_challenge\\src\\dataPipeline.py:42: DtypeWarning: Columns (3,4,5,6,11,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,45,46,47,49,50,107,110,114,115,116,119,120,121,124,125,126,128,131,132) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.data = pd.read_csv(filePath)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                    detailed_description  price_cleaned\n0      DescriptionLuxuriöse Attika-Wohnung direkt an ...      1150000.0\n1      DescriptionStilvolle Liegenschaft an ruhiger L...      1420000.0\n2      detail_responsive#description_title2,5 Zimmerw...       720000.0\n3      DescriptionDieses äusserst grosszügige Minergi...      1430000.0\n4      DescriptionAus ehemals zwei Wohnungen wurde ei...       995000.0\n...                                                  ...            ...\n22476  Description\\n\"Hausteil mit verschieden Nutzung...       475000.0\n22477  Description\\n\"J'ADORE - Exklusives Wohnen in W...      1490000.0\n22478  Description\\n\"Einmalige Gelegenheit an sehr gu...      1450000.0\n22479  Description\\n\"LA VIE - Exklusives Wohnen in Ma...      1290000.0\n22480  Description\\n\"Historisches Altstadthaus im \"St...       780000.0\n\n[22481 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>detailed_description</th>\n      <th>price_cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DescriptionLuxuriöse Attika-Wohnung direkt an ...</td>\n      <td>1150000.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>DescriptionStilvolle Liegenschaft an ruhiger L...</td>\n      <td>1420000.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>detail_responsive#description_title2,5 Zimmerw...</td>\n      <td>720000.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>DescriptionDieses äusserst grosszügige Minergi...</td>\n      <td>1430000.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DescriptionAus ehemals zwei Wohnungen wurde ei...</td>\n      <td>995000.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>22476</th>\n      <td>Description\\n\"Hausteil mit verschieden Nutzung...</td>\n      <td>475000.0</td>\n    </tr>\n    <tr>\n      <th>22477</th>\n      <td>Description\\n\"J'ADORE - Exklusives Wohnen in W...</td>\n      <td>1490000.0</td>\n    </tr>\n    <tr>\n      <th>22478</th>\n      <td>Description\\n\"Einmalige Gelegenheit an sehr gu...</td>\n      <td>1450000.0</td>\n    </tr>\n    <tr>\n      <th>22479</th>\n      <td>Description\\n\"LA VIE - Exklusives Wohnen in Ma...</td>\n      <td>1290000.0</td>\n    </tr>\n    <tr>\n      <th>22480</th>\n      <td>Description\\n\"Historisches Altstadthaus im \"St...</td>\n      <td>780000.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>22481 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from src.dataPipeline import DataPipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=10)\n",
    "\n",
    "os.chdir('..')\n",
    "\n",
    "\n",
    "columns_to_drop_all = [\n",
    "'Unnamed: 0.1', 'Unnamed: 0','Municipality','Living space',\n",
    "'Plot area','Floor space','location',\n",
    "'description',\n",
    "#'detailed_description',\n",
    "'url','table','detail_responsive#municipality',\n",
    "'detail_responsive#surface_living','detail_responsive#floor','detail_responsive#available_from',\n",
    "'Gemeinde','Wohnfläche','Stockwerk','Nutzfläche','Verfügbarkeit','Grundstücksfläche',\n",
    "'detail_responsive#surface_property','Commune','Surface habitable','Surface du terrain',\n",
    "'Surface utile','Disponibilité','Étage','Comune','Superficie abitabile','Disponibilità',\n",
    "'Piano','Superficie del terreno','Superficie utile','Municipality_merged',\n",
    "'Floor_merged','Living_space_merged','Plot_area_merged','Availability_merged','location_parsed',\n",
    "'title',\n",
    "'price','address','link','details_structured','index',\n",
    "'Locality','Zip','rooms','Floor_unified','Living_area_unified','space',\n",
    "'price_s','address_s','Surface living:','Land area:',\n",
    "'description_detailed','Floor space:','Volume:','plz','Number of toilets:','Gross yield:',\n",
    "'Minimum floor space:','space_cleaned'\n",
    "\n",
    "# Temporary columns\n",
    ", 'Gross return'\n",
    ", 'details'\n",
    ", 'Room height:'\n",
    ", 'features'\n",
    ", 'type'\n",
    ", 'provider' ,\n",
    "'type_unified',\n",
    "'Availability',\n",
    "'Floor',\n",
    "'detail_responsive#surface_usable',\n",
    "'Floor_space_merged',\n",
    "'lat',\n",
    "'lon',\n",
    "'ForestDensityL',\n",
    "'ForestDensityM',\n",
    "'ForestDensityS',\n",
    "'Latitude',\n",
    "'Longitude',\n",
    "'NoisePollutionRailwayL',\n",
    "'NoisePollutionRailwayM',\n",
    "'NoisePollutionRailwayS',\n",
    "'NoisePollutionRoadL',\n",
    "'NoisePollutionRoadM',\n",
    "'NoisePollutionRoadS',\n",
    "'PopulationDensityL',\n",
    "'PopulationDensityM',\n",
    "'PopulationDensityS',\n",
    "'RiversAndLakesL',\n",
    "'RiversAndLakesM',\n",
    "'RiversAndLakesS',\n",
    "'WorkplaceDensityL',\n",
    "'WorkplaceDensityM',\n",
    "'WorkplaceDensityS',\n",
    "'distanceToTrainStation',\n",
    "'gde_area_agriculture_percentage',\n",
    "'gde_area_forest_percentage',\n",
    "'gde_area_nonproductive_percentage',\n",
    "'gde_area_settlement_percentage',\n",
    "'gde_average_house_hold',\n",
    "'gde_empty_apartments',\n",
    "'gde_foreigners_percentage',\n",
    "'gde_new_homes_per_1000',\n",
    "'gde_politics_bdp',\n",
    "'gde_politics_cvp',\n",
    "'gde_politics_evp',\n",
    "'gde_politics_fdp',\n",
    "'gde_politics_glp',\n",
    "'gde_politics_gps',\n",
    "'gde_politics_pda',\n",
    "'gde_politics_rights',\n",
    "'gde_politics_sp',\n",
    "'gde_politics_svp',\n",
    "'gde_pop_per_km2',\n",
    "'gde_population',\n",
    "'gde_private_apartments',\n",
    "'gde_social_help_quota',\n",
    "'gde_tax',\n",
    "'gde_workers_sector1',\n",
    "'gde_workers_sector2',\n",
    "'gde_workers_sector3',\n",
    "'gde_workers_total',\n",
    "'plz_parsed',\n",
    "'No. of rooms:',\n",
    "'Number of apartments:',\n",
    "'Last refurbishment:',\n",
    "'Number of floors:',\n",
    "'Year built:',\n",
    "'Space extracted',\n",
    "'Plot_area_unified',\n",
    "\n",
    "]\n",
    "\n",
    "dp = DataPipeline()\n",
    "dp.readCsv(\"data/immo_data_202208_v2.csv\")\n",
    "dp.dropColumns(columns_to_drop_all)\n",
    "\n",
    "df = dp.getData()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# set the random seed to get comparable results\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "features = df['detailed_description']\n",
    "# Fill NaN values with empty string\n",
    "features = features.fillna('')\n",
    "target = df['price_cleaned']\n",
    "\n",
    "# Drop all columns with NaN values in price_cleaned\n",
    "features = features[target.notnull()]\n",
    "target = target[target.notnull()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T13:02:10.599297100Z",
     "start_time": "2024-11-17T13:02:10.576244700Z"
    }
   },
   "id": "57611c658697b95a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['00', '000', '0001', ..., 'œnothèque', 'œuvre', 'œuvres'],\n      dtype=object)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# prepare the data\n",
    "comments_train, comments_test, y_train, y_test = train_test_split(features, target, test_size = 0.3) \n",
    "\n",
    "# we use a count vectorizer to break the individual comments into tokens, one token per word\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(comments_train)\n",
    "\n",
    "# we create the training a matrix \n",
    "X_train = vectorizer.transform(comments_train)\n",
    "X_test = vectorizer.transform(comments_test)\n",
    "\n",
    "# train the classifier\n",
    "#classifier = LogisticRegression(max_iter=2000)\n",
    "#classifier.fit(X_train, y_train)\n",
    "vectorizer.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-17T13:08:48.906430700Z",
     "start_time": "2024-11-17T13:08:44.213743800Z"
    }
   },
   "id": "5c8a9fc25a1bf792",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "classifier = RandomForestRegressor()\n",
    "classifier.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-11-17T13:13:08.948897800Z"
    }
   },
   "id": "eb16d7f5aceed90"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#test the data\n",
    "score = classifier.score(X_test, y_test)\n",
    "print(\"Accuracy:\", score)\n",
    "\n",
    "#test the classifier with mape\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "y_pred = classifier.predict(X_test)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
    "print(\"MAPE:\", mape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a466c500353935aa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#plot the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, classifier.predict(X_test))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "873aaa4026f00be7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Embedding for Text with BERT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fab0c90bae43a2c6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch.nn as nn\n",
    "\n",
    "class BertForRegression(nn.Module):\n",
    "    def __init__(self, pretrained_model_name):\n",
    "        super(BertForRegression, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model_name)\n",
    "        self.regressor = nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_output = outputs.pooler_output  # `[CLS]` token output\n",
    "        return self.regressor(cls_output)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T14:09:13.190021500Z",
     "start_time": "2024-12-02T14:09:13.161950400Z"
    }
   },
   "id": "10fccb00c396d12b",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class RealEstateDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        description = self.dataframe.iloc[index]['detailed_description']\n",
    "        price = self.dataframe.iloc[index]['price_cleaned']\n",
    "\n",
    "        # Tokenisierung\n",
    "        encoding = self.tokenizer(\n",
    "            description,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),  # Entferne Batch-Dimension\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'target': torch.tensor(price, dtype=torch.float)\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T14:09:16.468159Z",
     "start_time": "2024-12-02T14:09:16.460307300Z"
    }
   },
   "id": "fe067b8490e3e417",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: nan\n",
      "Epoch 2, Training Loss: nan\n",
      "Epoch 3, Training Loss: nan\n",
      "Epoch 4, Training Loss: nan\n",
      "Epoch 5, Training Loss: nan\n",
      "Epoch 6, Training Loss: nan\n",
      "Epoch 7, Training Loss: nan\n",
      "Epoch 8, Training Loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 60\u001B[0m\n\u001B[0;32m     57\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     58\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 60\u001B[0m     train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     62\u001B[0m train_loss \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loader)\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Training Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src import torchModelRun\n",
    "import torch\n",
    "\n",
    "# Train BERT model\n",
    "\n",
    "model = BertForRegression('bert-base-uncased')\n",
    "\n",
    "epochs = 10\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "max_length = 128\n",
    "train_dataset = RealEstateDataset(train_df, tokenizer, max_length)\n",
    "test_dataset = RealEstateDataset(test_df, tokenizer, max_length)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#import sgd\n",
    "from torch.optim import SGD\n",
    "import torch.nn as nn\n",
    "\n",
    "# Modell initialisieren\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = BertForRegression('bert-base-uncased').to(device)\n",
    "\n",
    "# Optimizer und Verlustfunktion\n",
    "optimizer = SGD(model.parameters(), lr=1e-5)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Training\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        target = batch['target'].view(-1, 1).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-02T15:00:27.846465900Z",
     "start_time": "2024-12-02T14:22:40.834635500Z"
    }
   },
   "id": "eb0b02a703b27176",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "83ba7fbb03769325"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
